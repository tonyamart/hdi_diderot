---
title: "04_editions_tests"
format: html
editor: visual
---

## Testing data from different editions of HDI

```{r}
library(tidyverse)
library(tidytext)

theme_set(theme_minimal())
```

Load 1000 word chunks corpus

```{r}
corpus <- readRDS("../../data/bdi/corpus_chunks.rds")
glimpse(corpus)
```

Quick rearrangement to 2000 words chunks

```{r}
corpus <- corpus %>% 
  separate(chunk_id, into = c("chunk_num", "title"), sep = "__") %>% 
  separate(title, into = c("author", "work"), sep = "_") %>% 
  select(author, work, chunk_num, text) %>% 
  # fix Diderot into one set
  mutate(author = ifelse(author == "Diderot II", "Diderot", author)) %>% 
  
  # recalculate chunks
  mutate(chunk_num_2 = floor(as.numeric(chunk_num)/2)) %>% 
  mutate(tag = paste0(chunk_num_2, "__", author, "_", work)) 

# last 1k chunks (to be removed)
x <- corpus %>% 
  group_by(tag) %>% 
  count(chunk_num_2, sort = T) %>% 
  filter(n < 2) %>% 
  ungroup() %>% 
  pull(tag)

head(x)

raw_corpus <- corpus %>% 
  # remove chunks with less then 2k words
  select(-chunk_num_2) %>% 
  filter(!tag %in% x) %>% 
  mutate(chunk_num = str_extract(tag, "^\\d+"))
  
head(raw_corpus) # in this corpus each 2k chunk = 2 rows
```

Load problems: segments from HDI editions of 1770, 1774, and 1780.

```{r}
editions <- list.files(path = "../../data/test_fragments/",
                       pattern = "ed",
                       full.names = T)

editions

editions <- tibble(
  path = editions,
  title = editions,
  text = sapply(path, read_file)
) %>% 
  mutate(title = str_remove_all(title, "^\\.\\./\\.\\./data/test_fragments//|\\.txt"))

str(editions)
```

### Prep test data

Some cleaning

```{r}
# clean ' and search for &
# remove "appeared|changed|unchanged"

ed_tokens <- editions %>% 
  # replace ' and - with \s
  mutate(text_cln = str_replace_all(text, "'|-|_", " "),
         # replace newlines
         text_cln = str_replace_all(text_cln, "\\r|\\n", "  "),
         # lowercase
         text_cln = sapply(text_cln, tolower)) %>% #str
  # remove raw texts & paths
  select(-text, -path) %>% 
  rename(text = text_cln) %>% 
  
  # tokenisation
  unnest_tokens(input = text, output = word, token = "words") %>% 
  
  # remove working tags
  filter(!word %in% c("appeared", "changed", "unchanged")) %>% 
  # remove digits
  filter(!str_detect(word, "^\\d*$")) 

head(ed_tokens)
```

Number of words in each set (Table 2)

```{r}
glimpse(ed_tokens)

ed_tokens %>% 
  count(title, sort = F)
```

Create chunks – 2000 words

```{r}
ed_chunks <- ed_tokens %>% 
  group_by(title) %>% 
  mutate(id = row_number()-1,
         id_group = floor(id /2000)) %>% 
  ungroup()

head(ed_chunks)

# find chunks with less than 1000 words
x <- ed_chunks %>% 
  group_by(title, id_group) %>% 
  count() %>% 
  ungroup() %>% 
  filter(n < 2000) %>% 
  mutate(chunk_id = paste0(title, "__", id_group)) 

x # small chunks

ed_chunks <- ed_chunks %>% 
  mutate(chunk_id = paste0(title, "__", id_group)) %>% 
  # remove shorter chunks
  filter(!chunk_id %in% x$chunk_id) %>% 
  
  # concat text in each chunk
  select(chunk_id, word) %>% 
  group_by(chunk_id) %>% 
  mutate(text = paste(word, collapse = " ")) %>%
  select(-word) %>%
  distinct() %>%
  ungroup() %>% 
  # rename chunks (_ to -)
  mutate(chunk_id = str_replace_all(chunk_id, "_", "-"))

head(ed_chunks)

# count number of chunks
ed_chunks %>% 
  separate(col = chunk_id, into = c("title", "chunk_id"), sep = "--") %>% 
  count(title)

rm(editions, ed_tokens, x)
```

```{r}
# check data
ed_chunks$text[3]
```

Create columns for BDI test

```{r}
editions_chunks <- ed_chunks %>% 
  separate(col = chunk_id, into = c("work", "chunk_num"), sep = "--") %>% 
  mutate(author = "HDI") %>% 
  mutate(tag = paste0(chunk_num, "__", author, "_", work)) %>% 
  select(author, work, chunk_num, text, tag) 

head(editions_chunks)
```

Prepare reference set in the same way & attach problem sets

```{r}
raw_corpus <- raw_corpus %>% 
  # separate(chunk_id, into = c("chunk_num", "title"), sep = "__") %>% 
  # separate(title, into = c("author", "work"), sep = "_") %>% 
  # select(author, work, chunk_num, text) %>% 
  rbind(editions_chunks) 

head(raw_corpus)
```

### count freq & write data

```{r}
# editions groupings
raw_corpus %>% 
  filter(author == "HDI") %>% 
  pull(work) %>% 
  unique()

# c("ed1770-nch1774-nch1780", "ed1770-CH1774-nch1780", "ed1770-nch1774-CH1780", "ed1770-CH1774-CH1780",  "ed1774-nch1780", "ed1774-CH1780", "ed1780" )
```

Number of chunks in each group

```{r}
raw_corpus %>% 
  filter(author == "HDI") %>% 
  group_by(work) %>% 
  count()
```

#### ed1770-nch1774-nch1780

Select problems chunks; calculate ranks & frequencies

```{r}
# remove other problems from the corpus
t <- raw_corpus %>% 
  filter(!work %in% c(# "ed1770-nch1774-nch1780", 
                      # "ed1770-CH1774-nch1780", 
                      "ed1770-nch1774-CH1780", 
                      "ed1770-CH1774-CH1780",  
                      "ed1774-nch1780", 
                      "ed1774-CH1780", 
                      "ed1780")) 

###################### freqs

# total words
total <- t %>% 
  unnest_tokens(input = text, output = word, token = "words") %>% 
  nrow()

# check ranks for the 200 MFW
ranks <- t %>% 
  unnest_tokens(input = text, output = word, token = "words") %>% 
  count(word, sort = T) %>% 
  mutate(rel_freq = (n / total) * 100 ) %>% 
  head(250)

head(ranks, 10)

# set MFW number
mfw <- ranks$word[1:200]

# calculate relative frequencies in each chunk
rfreq <- t %>% 
  unnest_tokens(input = text, output = word, token = "words") %>% 
  # filter 100 MFW
  filter(word %in% mfw) %>% 
  # count words in each chunk
  group_by(tag) %>% 
  count(word, sort = T) %>% 
  ungroup() %>% 
  # calculate relative freq
  mutate(rel_freq = n/2000 * 100) %>% 
  # transform to wide matrix-like table
  select(-n) %>% 
  pivot_wider(names_from = word, values_from = rel_freq, values_fill = 0) %>% 
  arrange(-desc(tag))

rfreq[1:5, 1:5]

dim(rfreq)

#################### save
# extract metadata back as separate columns (from tag-merged freqs already!)
meta_cols <- rfreq %>% 
  select(tag) %>% 
  separate(remove = FALSE, col = tag, into = c("chunk_num", "othr"), sep = "__") %>% 
  separate(col = "othr", into = c("author", "work"), sep = "_") %>% 
  select(work, author, chunk_num, tag)

head(meta_cols)

# attach metadata cols to word freqs
rfreq <- meta_cols %>% 
  left_join(rfreq, by = "tag")

dim(rfreq)

write.csv(rfreq, "04_tests/ed1770-nch-nch_2k_200mfw_rfreq.csv", 
          row.names = F)
```

#### ed1770-CH1774-nch1780

```{r}
# remove other problems from the corpus
t <- raw_corpus %>% 
  filter(!work %in% c("ed1770-nch1774-nch1780", 
                      # "ed1770-CH1774-nch1780", 
                      # "ed1770-nch1774-CH1780", 
                      "ed1770-CH1774-CH1780",  
                      "ed1774-nch1780", 
                      "ed1774-CH1780", 
                      "ed1780")) 

###################### freqs

# total words
total <- t %>% 
  unnest_tokens(input = text, output = word, token = "words") %>% 
  nrow()

# check ranks for the 200 MFW
ranks <- t %>% 
  unnest_tokens(input = text, output = word, token = "words") %>% 
  count(word, sort = T) %>% 
  mutate(rel_freq = (n / total) * 100 ) %>% 
  head(250)

head(ranks, 10)

# set MFW number
mfw <- ranks$word[1:200]

# calculate relative frequencies in each chunk
rfreq <- t %>% 
  unnest_tokens(input = text, output = word, token = "words") %>% 
  # filter 100 MFW
  filter(word %in% mfw) %>% 
  # count words in each chunk
  group_by(tag) %>% 
  count(word, sort = T) %>% 
  ungroup() %>% 
  # calculate relative freq
  mutate(rel_freq = n/2000 * 100) %>% 
  # transform to wide matrix-like table
  select(-n) %>% 
  pivot_wider(names_from = word, values_from = rel_freq, values_fill = 0) %>% 
  arrange(-desc(tag))

rfreq[1:5, 1:5]

dim(rfreq)

#################### save
# extract metadata back as separate columns (from tag-merged freqs already!)
meta_cols <- rfreq %>% 
  select(tag) %>% 
  separate(remove = FALSE, col = tag, into = c("chunk_num", "othr"), sep = "__") %>% 
  separate(col = "othr", into = c("author", "work"), sep = "_") %>% 
  select(work, author, chunk_num, tag)

head(meta_cols)

# attach metadata cols to word freqs
rfreq <- meta_cols %>% 
  left_join(rfreq, by = "tag")

dim(rfreq)

write.csv(rfreq, "04_tests/ed1770-CH-nch_2k_200mfw_rfreq.csv", 
          row.names = F)
```

### fn for counting frequencies

```{r}
count_rfreq <- function(tbl, n_mfw, chunk_size) {
    ###################### freqs
  
  # total words
  total <- tbl %>% 
    unnest_tokens(input = text, output = word, token = "words") %>% 
    nrow()
  
  # check ranks for the 200 MFW
  ranks <- tbl %>% 
    unnest_tokens(input = text, output = word, token = "words") %>% 
    count(word, sort = T) %>% 
    mutate(rel_freq = (n / total) * 100 ) %>% 
    head(250)
  
  # head(ranks, 10)
  
  # set MFW number
  mfw <- ranks$word[1:n_mfw]
  
  # calculate relative frequencies in each chunk
  rfreq <- t %>% 
    unnest_tokens(input = text, output = word, token = "words") %>% 
    # filter 100 MFW
    filter(word %in% mfw) %>% 
    # count words in each chunk
    group_by(tag) %>% 
    count(word, sort = T) %>% 
    ungroup() %>% 
    # calculate relative freq
    mutate(rel_freq = n/chunk_size * 100) %>% 
    # transform to wide matrix-like table
    select(-n) %>% 
    pivot_wider(names_from = word, values_from = rel_freq, values_fill = 0) %>% 
    arrange(-desc(tag))
  
  # rfreq[1:5, 1:5]
  
  # dim(rfreq)
  
  #################### save
  # extract metadata back as separate columns (from tag-merged freqs already!)
  meta_cols <- rfreq %>% 
    select(tag) %>% 
    separate(remove = FALSE, col = tag, 
             into = c("chunk_num", "othr"), sep = "__") %>% 
    separate(col = "othr", into = c("author", "work"), sep = "_") %>% 
    select(work, author, chunk_num, tag)
  
  # head(meta_cols)
  
  # attach metadata cols to word freqs
  rfreq <- meta_cols %>% 
    left_join(rfreq, by = "tag")
  
  # dim(rfreq)
  
  return(rfreq)
}

```

#### ed1770-nch-CH

```{r}
# remove other problems from the corpus
t <- raw_corpus %>% 
  filter(!work %in% c("ed1770-nch1774-nch1780", 
                      "ed1770-CH1774-nch1780", 
                      # "ed1770-nch1774-CH1780", 
                      # "ed1770-CH1774-CH1780",  
                      "ed1774-nch1780", 
                      "ed1774-CH1780", 
                      "ed1780")) 

ed1770_nch_ch_rfreq <- count_rfreq(t, n_mfw = 200, chunk_size = 2000)

ed1770_nch_ch_rfreq[1:5,1:5]

write.csv(ed1770_nch_ch_rfreq, "04_tests/ed1770-nch-CH_2k_200mfw_rfreq.csv", 
          row.names = F)
```

#### ed1700-CH-CH

```{r}
# remove other problems from the corpus
t <- raw_corpus %>% 
  filter(!work %in% c("ed1770-nch1774-nch1780", 
                      "ed1770-CH1774-nch1780", 
                      "ed1770-nch1774-CH1780", 
                      # "ed1770-CH1774-CH1780",  
                      # "ed1774-nch1780", 
                      "ed1774-CH1780", 
                      "ed1780")) 

ed1770_ch_ch_rfreq <- count_rfreq(t, n_mfw = 200, chunk_size = 2000)

ed1770_ch_ch_rfreq[1:5,1:5]

write.csv(ed1770_ch_ch_rfreq, "04_tests/ed1770-CH-CH_2k_200mfw_rfreq.csv", 
          row.names = F)
```

#### ed1774-nch

```{r}
# remove other problems from the corpus
t <- raw_corpus %>% 
  filter(!work %in% c("ed1770-nch1774-nch1780", 
                      "ed1770-CH1774-nch1780", 
                      "ed1770-nch1774-CH1780", 
                      "ed1770-CH1774-CH1780",  
                      # "ed1774-nch1780", 
                      # "ed1774-CH1780", 
                      "ed1780")) 

ed1774_nch_rfreq <- count_rfreq(t, n_mfw = 200, chunk_size = 2000)

ed1774_nch_rfreq[1:5,1:5]

write.csv(ed1774_nch_rfreq, "04_tests/ed1774_nch_2k_200mfw_rfreq.csv", 
          row.names = F)
```

#### ed1774-CH

```{r}
# remove other problems from the corpus
t <- raw_corpus %>% 
  filter(!work %in% c("ed1770-nch1774-nch1780", 
                      "ed1770-CH1774-nch1780", 
                      "ed1770-nch1774-CH1780", 
                      "ed1770-CH1774-CH1780",  
                      "ed1774-nch1780"#, 
                      # "ed1774-CH1780", 
                      # "ed1780"
                      )) 

ed1774_CH_rfreq <- count_rfreq(t, n_mfw = 200, chunk_size = 2000)

ed1774_CH_rfreq[1:5,1:5]

write.csv(ed1774_CH_rfreq, "04_tests/ed1774_CH_2k_200mfw_rfreq.csv", 
          row.names = F)
```

#### ed1780

```{r}
# remove other problems from the corpus
t <- raw_corpus %>% 
  filter(!work %in% c(#"ed1770-nch1774-nch1780", 
                      "ed1770-CH1774-nch1780", 
                      "ed1770-nch1774-CH1780", 
                      "ed1770-CH1774-CH1780",  
                      "ed1774-nch1780", 
                      "ed1774-CH1780"#, 
                      # "ed1780"
                      )) 

ed1780_rfreq <- count_rfreq(t, n_mfw = 200, chunk_size = 2000)

ed1780_rfreq[1:5,1:5]

write.csv(ed1774_CH_rfreq, "04_tests/ed1780_2k_200mfw_rfreq.csv", 
          row.names = F)
```

# Results

### fn for plt

```{r}
# make table ready for the ggplot from path=pth
compile_res <- function(pth, ptrn) {
  # list csv results
  fl <- list.files(path = pth, 
                   pattern = ptrn, full.names = T)
  
  new_data <- purrr::map_df(fl, function(x) {
    mydata <- read.csv(x)
    mydata %>% pivot_longer(!X, names_to = "run", values_to = "bdi") %>% 
    mutate(group = x)
  })
  
  return(new_data)
}

# make plot
mkplot <- function(plot_data, work) {
  
  plot_data %>% 
    mutate(group = str_remove_all(group, "04_tests/tests//|\\.csv")) %>% 
    ggplot(aes(x = bdi, group = run)) + 
    geom_density(alpha = 0.15, fill = "darkgreen", colour = "black") + 
    geom_vline(xintercept=0, lty = 2, colour = "black") + 
    facet_wrap(~group, ncol=1) + 
    theme(legend.position = "None") + 
    labs(title = paste0(work, " vs various authors (2k chunks, 200 MFW)"))
}

# mkplot(x, "ed1770-CH-nch")

# plot with selected authors
mk_splot <- function(plot_data, work, authors) {
  
  plot_data %>% 
    mutate(group = str_remove_all(group, "04_tests/tests//|\\.csv")) %>% 
    filter(str_detect(group, authors)) %>% 
    ggplot(aes(x = bdi, group = run, colour = group, fill = group)) + 
    geom_density(alpha = 0.3) + 
    geom_vline(xintercept=0, lty = 2, colour = "black") + 
    #geom_vline(xintercept=0.1, lty = 2, colour = "black") + 
    facet_wrap(~group, ncol=1) + 
    theme(legend.position = "None") + 
    labs(title = paste0(work, " vs various authors (2k chunks, 200 MFW)"))
}

# e.g.:
# mk_splot(x, work = "ed1770-CH-nch", authors = "HDI|Diderot|Raynal|dHolbach")
```

#### ed1770-nch1774-nch1780

5 chunks

```{r}
plt <- compile_res("04_tests/tests/", ptrn = "^ed1770-nch-nch")

mkplot(plt, "ed1770-nch-nch")

# ggsave(filename = "04_tests/plots/ed1770-nch-nch_2k_200MFW.png", 
#        plot = last_plot(),
#        height = 20, width = 8, bg = "white")
```

```{r}
fig_2b <- plt %>% 
  mutate(group = str_remove_all(group, "04_tests/tests//|\\.csv")) %>% 
  filter(str_detect(group, "Diderot|Rivière|Condorcet|dHolbach|Saint-Lambert|Meister|Deleyre|Pechmeja|Baudeau")) %>% 
  mutate(gr = ifelse(str_detect(group, "Diderot"), "d", "no")) %>% 
  mutate(group = ifelse(group == "ed1770-nch-nch_vs_dHolbach", "ed1770-nch-nch_vs_d'Holbach", group)) %>% 
  mutate(group = ifelse(group == "ed1770-nch-nch_vs_Rivière", "ed1770-nch-nch_vs_La Rivière", group)) %>%
  ggplot(aes(x = bdi, group = run, colour = gr, fill = gr)) + 
  geom_density(alpha = 0.5) + 
  geom_vline(xintercept=0, lty = 2, colour = "black") + 
  
  scale_color_manual(values = met.brewer("Kandinsky")[2:4]) + 
  scale_fill_manual(values = met.brewer("Kandinsky")[2:4]) + 
  #geom_vline(xintercept=0.1, lty = 2, colour = "black") + 
  facet_wrap(~group, ncol=1) + 
  theme(legend.position = "None") + 
  labs(title = "FP vs selected authors",
       y = "") + 
  theme(strip.text = element_text(size = 12),
        plot.subtitle = element_text(size = 14))

fig_2b

ggsave("../../hdi_diderot/scr/plots_paper/fig_2-b.png",
       plot = last_plot(), dpi = 300, bg = "white",
       height = 8, width = 6)
```

```{r}
plot_grid(fig_2a, fig_2b, 
          ncol = 2,
          labels = c('A', 'B'),
          label_size = 24,
          rel_widths = c(4, 3))

ggsave("../plots_paper/fig_2.png",
       bg = "white", dpi = 300,
       height = 8, width = 14)
```

mass above zero

```{r}
plt %>% 
  mutate(group = str_remove_all(group, "04_tests/tests//ed1770-nch-nch_vs_|\\.csv")) %>% 
  # filter(group == "fp1_vs_Baudeau") %>% 
  mutate(above_0 = bdi>0) %>%  
  group_by(group, run) %>% 
  summarise(perc_above_0 = (sum(above_0) / 1000) * 100) %>% 
  ungroup() %>% 
  group_by(group) %>% 
  summarise(mean_above_0 = mean(perc_above_0)) %>% 
  # arrange by top mean
  arrange(desc(mean_above_0))
```

#### ed1770-CH1774-nch1780

2 chunks

```{r}
plt <- compile_res("04_tests/tests/", ptrn = "^ed1770-CH-nch")

mkplot(plt, "ed1770-CH-nch")

ggsave(filename = "04_tests/plots/ed1770-CH-nch_2k_200MFW.png", 
       plot = last_plot(),
       height = 20, width = 8, bg = "white")

mk_splot(plt, work = "ed1770-CH-nch", authors = "HDI|Diderot|Raynal|dHolbach")
```

#### ed1770-nch1774-CH1780

9 chunks

```{r}
# gather data
plt <- compile_res("04_tests/tests/", ptrn = "^ed1770-nch-CH")

# create and save plot with results for all authors
mkplot(plt, "ed1770-nch-CH")

ggsave(filename = "04_tests/plots/ed1770-nch-CH_2k_200MFW.png", 
       plot = last_plot(),
       height = 20, width = 8, bg = "white")

# short version of the plot
mk_splot(plt, work = "ed1770-nch-CH", authors = "HDI|Diderot|Raynal|dHolbach")
```

#### ed1770-CH1774-CH1780

8 chunks

```{r}
# gather data
plt <- compile_res("04_tests/tests/", ptrn = "^ed1770-CH-CH")

# create and save plot with results for all authors
mkplot(plt, "ed1770-CH-CH")

ggsave(filename = "04_tests/plots/ed1770-CH-CH_2k_200MFW.png", 
       plot = last_plot(),
       height = 20, width = 8, bg = "white")

# short version of the plot
mk_splot(plt, work = "ed1770-CH-CH", authors = "HDI|Diderot|Raynal|dHolbach")
```

#### ed1774-nch1780

2 chunks

```{r}
# gather data
plt <- compile_res("04_tests/tests/", ptrn = "^ed1774-nch")

# create and save plot with results for all authors
mkplot(plt, "ed1774-nch")

ggsave(filename = "04_tests/plots/ed1774-nch_2k_200MFW.png", 
       plot = last_plot(),
       height = 20, width = 8, bg = "white")

# short version of the plot
mk_splot(plt, work = "ed1774-nch", authors = "HDI|Diderot|Raynal|dHolbach")
```

#### ed1774-CH1780

9 chunks

```{r}
# gather data
plt <- compile_res("04_tests/tests/", ptrn = "^ed1774-CH")

# create and save plot with results for all authors
mkplot(plt, "ed1774-CH")

ggsave(filename = "04_tests/plots/ed1774-CH_2k_200MFW.png", 
       plot = last_plot(),
       height = 20, width = 8, bg = "white")

# short version of the plot
mk_splot(plt, work = "ed1774-CH", authors = "HDI|Diderot|Raynal|dHolbach")
```

#### ed1780

42 chunks

```{r}
# gather data
plt <- compile_res("04_tests/tests/", ptrn = "^ed1780")

# create and save plot with results for all authors
mkplot(plt, "ed1780")

ggsave(filename = "04_tests/plots/ed1780_2k_200MFW.png", 
       plot = last_plot(),
       height = 20, width = 8, bg = "white")

# short version of the plot
mk_splot(plt, work = "ed1780", authors = "HDI|Diderot|Raynal|dHolbach")
```
